{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k2vvhdotdD7-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, test_data), info = tfds.load(\n",
        "    'imdb_reviews',\n",
        "    split=[tfds.Split.TRAIN, tfds.Split.TEST],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "train_sentences, train_labels = zip(*[(sent.numpy().decode('utf8'), label.numpy()) for sent, label in train_data])\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "train_padded = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=100, padding='post', truncating='post')\n",
        "\n",
        "test_sentences, test_labels = zip(*[(sent.numpy().decode('utf8'), label.numpy()) for sent, label in test_data])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=100, padding='post', truncating='post')\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "HfIjHQrDdiyc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(10000, 64),\n",
        "    keras.layers.SimpleRNN(64),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWrqL24Ud2WC",
        "outputId": "ca083544-a787-4177-e9ae-4dc7d5fb6ea9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 40ms/step - accuracy: 0.5183 - loss: 0.6932 - val_accuracy: 0.6602 - val_loss: 0.6436\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.6544 - loss: 0.6328 - val_accuracy: 0.7080 - val_loss: 0.5912\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.6881 - loss: 0.5939 - val_accuracy: 0.5420 - val_loss: 0.7260\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.6798 - loss: 0.5864 - val_accuracy: 0.5547 - val_loss: 0.7235\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.7453 - loss: 0.5125 - val_accuracy: 0.6820 - val_loss: 0.6458\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7807 - loss: 0.4561 - val_accuracy: 0.5363 - val_loss: 0.7495\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 41ms/step - accuracy: 0.7481 - loss: 0.4926 - val_accuracy: 0.5328 - val_loss: 0.7444\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.7192 - loss: 0.5249 - val_accuracy: 0.5294 - val_loss: 0.8301\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - accuracy: 0.7819 - loss: 0.4371 - val_accuracy: 0.5738 - val_loss: 0.8722\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.8268 - loss: 0.3730 - val_accuracy: 0.6622 - val_loss: 0.7835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_padded, test_labels, verbose=0)\n",
        "print(f\"Test accuracy: {score[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npcRfq3md5H6",
        "outputId": "fb1cf84d-5722-47ef-e262-9561dc7af619"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review_text):\n",
        "    text = review_text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(seq, maxlen=200)\n",
        "\n",
        "    prediction = model.predict(padded)[0][0]\n",
        "    return f\"{'Positive' if prediction >= 0.5 else 'Negative'} (Probability: {prediction:.2f})\"\n",
        "\n",
        "sample_review = \"great movie.\"\n",
        "print(f\"Review: {sample_review}\")\n",
        "print(f\"Sentiment: {predict_sentiment(sample_review)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiuE6CPrd-gi",
        "outputId": "fae64a3f-891c-4222-ac3d-22c76666e286"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: great movie.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Sentiment: Negative (Probability: 0.15)\n"
          ]
        }
      ]
    }
  ]
}